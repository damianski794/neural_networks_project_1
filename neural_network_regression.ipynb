{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIECI NEURONOWE, PROJEKT 1\n",
    "#### Autorzy: Mikołaj Rzepiński, Damian Wysokiński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wybór liczby warstw i liczby węzłów w każdej warstwie\n",
    "\n",
    "Wybór liczby węzłów w warstwie zerowej (input layer) zależy od rodzaju problemu - czy mamy regresję, czy klasyfikację oraz od liczby kolumn z danymi pobieranymi z plików csv. Analogiczna sytuacja jest z ostatnią warstwą (output layer). Ponadto w warstwie ostatniej wybiera się funkcję aktywacji stosowną do problemu:\n",
    "- dla regresji (funkcja liniowa)\n",
    "- dla klasyfikacji (softmax, liczba węzłów zależna od liczby unikalnych wartości w zbiorze uczącym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dla regresji\n",
    "\n",
    "Mamy 2 możliwości:\n",
    "- x - > y\n",
    "- x, y -> z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_problem = True\n",
    "classification_problem = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_bias = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x          y\n",
      "0  2.895004  -5.244196\n",
      "1 -0.258565 -18.416880\n",
      "2  3.637549   3.854040\n",
      "3  4.082869  19.670249\n",
      "4 -1.122748 -80.844386\n"
     ]
    }
   ],
   "source": [
    "#dodac dostosowanie do tego czy jest to plik do regresji czy klasyfikacji\n",
    "\n",
    "if(regression_problem):\n",
    "    regression_train_file = 'regression\\data.cube.train.1000.csv' #jak działasz na linuxie to musisz dostosować \\ na /\n",
    "    regression_df = pd.read_csv(regression_train_file)\n",
    "    print(regression_df.head())\n",
    "    \n",
    "    regression_test_file = 'regression\\data.cube.test.1000.csv'\n",
    "    regression_test_df = pd.read_csv(regression_test_file)\n",
    "    \n",
    "#regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(classification_problem):\n",
    "    classification_train_file = 'classification\\data.three_gauss.test.100.csv'\n",
    "    #classification_train_file = 'classification\\data.simple.test.10000.csv'\n",
    "    classification_df = pd.read_csv(classification_train_file)\n",
    "    \n",
    "    print(classification_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_softmax_array(values_array):\n",
    "    y_train_normal_labels = values_array.to_numpy().reshape(1,-1)\n",
    "    \n",
    "    unique_values = np.unique(y_train_normal_labels)\n",
    "     \n",
    "    softmax_list = []\n",
    "    for idx, unique_value in enumerate(unique_values):\n",
    "        softmax_list.append(y_train_normal_labels == unique_value)\n",
    "        \n",
    "    return np.array(softmax_list).astype('float').reshape(len(unique_values),y_train_normal_labels.shape[1]).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(classification_problem):\n",
    "    x_train = classification_df[['x','y']].to_numpy().T\n",
    "    y_train = create_softmax_array(classification_df['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(regression_problem):\n",
    "    x_train = np.array(regression_df['x']).reshape(1,-1)\n",
    "    y_train = np.array(regression_df['y']).reshape(1,-1)\n",
    "    \n",
    "    x_test = np.array(regression_test_df['x']).reshape(1,-1)\n",
    "    y_test = np.array(regression_test_df['y']).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "if(regression_problem):\n",
    "    print(regression_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_nodes': 1, 'activation_function': None},\n",
       " {'n_nodes': 1, 'activation_function': 'linear'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(regression_problem):\n",
    "    n_nodes_input_layer = 1\n",
    "    output_layer_activation_function = \"linear\"\n",
    "elif(classification_problem):\n",
    "    n_nodes_input_layer = 2\n",
    "    output_layer_activation_function = \"softmax\"\n",
    "    \n",
    "\n",
    "input_layer = [\n",
    "    {\n",
    "        \"n_nodes\": n_nodes_input_layer,\n",
    "        \"activation_function\": None\n",
    "    },\n",
    "]\n",
    "\n",
    "hidden_layers = [\n",
    "    #{\n",
    "     #   \"n_nodes\": 2,\n",
    "      #  \"activation_function\": \"relu\"#\"relu\" \n",
    "    #},\n",
    "    #{\n",
    "    #    \"n_nodes\": 4,\n",
    "    #    \"activation_function\": \"relu\"#\"relu\"\n",
    "    #}\n",
    "]\n",
    "\n",
    "if(regression_problem):\n",
    "    n_nodes_output_layer = 1\n",
    "elif(classification_problem):\n",
    "    n_nodes_output_layer = 3\n",
    "    \n",
    "output_layer = [\n",
    "    {\n",
    "        \"n_nodes\": n_nodes_output_layer,\n",
    "        \"activation_function\": output_layer_activation_function\n",
    "    }, ]\n",
    "\n",
    "layers = input_layer + hidden_layers + output_layer\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W zależności od tego czy chcemy uwzględnić bias w sieci można zmieniać wartość include bias jako True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(x_train, layers, include_bias = True):\n",
    "    # zwraca slownik z wagami i biasami np. parameters['w1'], parameters['b1']\n",
    "    #print(x_train.shape)\n",
    "    #print()\n",
    "    np.random.seed(42) # jeśli chcemy za każdym razem te same wyniki\n",
    "    \n",
    "    n_features = x_train.shape[0]\n",
    "    n_examples = x_train.shape[1]\n",
    "    \n",
    "    n_layers = len(layers) # 1 dla input layer, 1 dla output layer\n",
    "#     print(n_layers)\n",
    "    \n",
    "    parameters = {}\n",
    "    activation_values = {}\n",
    "    \n",
    "    \n",
    "    activation_values['0'] = x_train # wartosci x_train są jednocześnie wartościami aktywacji w zerwowej warstwie\n",
    "    \n",
    "    for n_layer in range(1,n_layers):\n",
    "        #print(n_layer)\n",
    "        #print(layers[n_layer])\n",
    "        parameters[\"W\" + str(n_layer)] = np.random.randn(layers[n_layer][\"n_nodes\"], layers[n_layer-1][\"n_nodes\"]) * 0.01 #wczesniej\n",
    "        if(include_bias):\n",
    "            parameters[\"b\" + str(n_layer)] = np.zeros((layers[n_layer][\"n_nodes\"],1))\n",
    "#         print(parameters[\"W\" + str(n_layer)])\n",
    "     \n",
    "#     print(parameters)\n",
    "    return parameters, activation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USUNALEM\n",
    "#parameters, activation_values = initialize_parameters(x_train,layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_forward(parameters, activation_values, z_values,  index_of_layer):\n",
    "    z_values[str(index_of_layer)] = np.dot(parameters['W' + str(index_of_layer)],\n",
    "                                                 activation_values[str(index_of_layer -1)]) + parameters['b' + str(index_of_layer)]\n",
    "#     print(parameters['Z'+str(index_of_layer)])\n",
    "#     print()\n",
    "#     print(parameters['Z'+str(index_of_layer)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_forward(parameters, activation_values, {'xd': 1}, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+ np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def leaky_relu(x):\n",
    "    return np.maximum(0.1*x, x)\n",
    "\n",
    "def linear(x):\n",
    "    return x;\n",
    "\n",
    "# do zweryfikowania ze wzgledu na obliczanie wzgledem okreslonego wektora(axis)\n",
    "def softmax(x):\n",
    "    expo = np.exp(x)\n",
    "    expo_sum = np.sum(np.exp(x))\n",
    "    return expo/expo_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_activation(z, activation_values, activation_function, index):\n",
    "    if(activation_function == 'linear'):\n",
    "        activation_values[str(index)] = linear(z)\n",
    "        \n",
    "    elif(activation_function == 'sigmoid'):\n",
    "        activation_values[str(index)] = sigmoid(z)\n",
    "        \n",
    "    elif(activation_function == 'relu'):\n",
    "        activation_values[str(index)] = relu(z)\n",
    "        \n",
    "    elif(activation_function == 'leaky_relu'):\n",
    "        activation_values[str(index)] = leaky_relu(z)\n",
    "        \n",
    "    elif(activation_function == 'softmax'):\n",
    "        activation_values[str(index)] = softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_functions(layers):\n",
    "    activation_functions = {}\n",
    "    for idx, layer in enumerate(layers):\n",
    "        activation_functions[str(idx)] = layer['activation_function']\n",
    "    \n",
    "    return activation_functions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': None, '1': 'linear'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_activation_functions(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **activation_values** to słownik zawierający: klucze -> numer warstwy, wartość -> macierz z wartościami aktywacji obliczonymi dla danej warstwy\n",
    "- **activation_functions** to słownik zawierający: klucze -> numer warstwy, wartość -> nazwa funkcji aktywacji dla danej warstwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_layers_forward_propagation(parameters, activation_values, activation_functions, z_values, no_of_layers):\n",
    "    for idx in range(1, no_of_layers):\n",
    "        z_forward(parameters, activation_values, z_values,  idx)\n",
    "        forward_with_activation(z_values[str(idx)], activation_values, activation_functions[str(idx)], idx)\n",
    "        #print('')\n",
    "    \n",
    "    return activation_values[str(no_of_layers - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_derivative():\n",
    "    return 1\n",
    "\n",
    "def relu_derivative(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def leaky_relu_derivative(x):\n",
    "    x[x<=0] = 0.1\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def softmax_derivative(x):\n",
    "    #to be implemented\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_layers_back_propagation_hardcoded_regression(y_true, parameters, gradients, activation_values, activation_functions, z_values, no_of_layers):\n",
    "    \n",
    "    m = y_true.shape[1]\n",
    "    \n",
    "    # WARSTWA 3\n",
    "    gradients['dZ3'] = (activation_values['3'] - y_true) * 1 # 1 bo to pochodna funkcji liniowej\n",
    "    gradients['dW3'] = 1/m * np.dot(gradients['dZ3'], activation_values['2'].T)\n",
    "    gradients['db3'] = 1/m * np.sum(gradients['dZ3'], axis=1, keepdims=True)\n",
    "    \n",
    "    # WARSTWA 2\n",
    "    gradients['dZ2'] = np.dot(parameters['W3'].T, gradients['dZ3']) * relu_derivative(activation_values['2']) \n",
    "    gradients['dW2'] = 1/m * np.dot(gradients['dZ2'], activation_values['1'].T)\n",
    "    gradients['db2'] = 1/m * np.sum(gradients['dZ2'], axis=1, keepdims=True)\n",
    "    \n",
    "    # WARSTWA 1\n",
    "    gradients['dZ1'] = np.dot(parameters['W2'].T, gradients['dZ2']) * relu_derivative(activation_values['1']) \n",
    "    gradients['dW1'] = 1/m * np.dot(gradients['dZ1'], activation_values['0'].T)\n",
    "    gradients['db1'] = 1/m * np.sum(gradients['dZ1'], axis=1, keepdims=True)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_layer_back_propagation(gradients, activation_values, activation_functions, z_values, error_type, index, y_true):\n",
    "    m = y_true.shape[1]\n",
    "    \n",
    "    if(activation_functions[str(index)] == 'linear'):\n",
    "        #print('calling last layer, linear activation', 'index:', index)\n",
    "        activation_function_derivative = linear_derivative()\n",
    "        \n",
    "    elif(activation_functions[str(index)] == 'relu'):\n",
    "        activation_function_derivative = relu_derivative(activation_values[str(index)])\n",
    "        \n",
    "    elif(activation_functions[str(index)] == 'leaky_relu'):\n",
    "        activation_function_derivative = leaky_relu_derivative(activation_values[str(index)])\n",
    "    \n",
    "    if(error_type == 'MSE'):\n",
    "        #print('activation_function_derivative w ostatniej warstwie  - automated')\n",
    "        #print(activation_function_derivative)\n",
    "        \n",
    "        gradients['dZ' + str(index)] = (activation_values[str(index)] - y_true) * activation_function_derivative \n",
    "#     print(\"gradients['dZ3'].shape\", gradients['dZ3'].shape)\n",
    "        gradients['dW' + str(index)] = 1/m * np.dot(gradients['dZ'+str(index)], activation_values[str(index - 1)].T)\n",
    "        gradients['db' + str(index)] = 1/m * np.sum(gradients['dZ'+str(index)], axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid_layer_back_propagation(gradients, activation_values, activation_functions, z_values, error_type, index, y_true):\n",
    "    m = y_true.shape[1]\n",
    "    \n",
    "    if(activation_functions[str(index)] == 'linear'):\n",
    "        activation_function_derivative = linear_derivative()\n",
    "        \n",
    "    elif(activation_functions[str(index)] == 'relu'):\n",
    "        #print('calling mid layer, relu activation', 'index:', index)\n",
    "        activation_function_derivative = relu_derivative(activation_values[str(index)])\n",
    "        \n",
    "    elif(activation_functions[str(index)] == 'leaky_relu'):\n",
    "        activation_function_derivative = leaky_relu_derivative(activation_values[str(index)])\n",
    "    \n",
    "     # WARSTWA 1 lub 2\n",
    "        #index = 1 lub 2\n",
    "    if(error_type == 'MSE'):\n",
    "        gradients['dZ' + str(index)] = np.dot(parameters['W'+str(index + 1)].T, gradients['dZ'+str(index+1)]) #* relu_derivative(activation_values[str(index)])#activation_function_derivative\n",
    "#     print(\"gradients['dZ3'].shape\", gradients['dZ3'].shape)\n",
    "        gradients['dW'+str(index)] = 1/m * np.dot(gradients['dZ'+str(index)], activation_values[str(index - 1)].T)\n",
    "        gradients['db'+str(index)] = 1/m * np.sum(gradients['dZ'+str(index)], axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid_layer_back_propagation_vol_two(parameters, gradients, activation_values, activation_functions, z_values, error_type, index, y_true):\n",
    "    # BO NAJWAZNIEJSZE JEST TYLKO TO ZEBY PODAWAC PARAMETERS JAKO ARGUMENT\n",
    "    \n",
    "    m = y_true.shape[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #PONIZEJ POPRAWNE HARDCODED\n",
    "        # WARSTWA 3\n",
    "    #gradients['dZ3'] = (activation_values['3'] - y_true) * 1 # 1 bo to pochodna funkcji liniowej\n",
    "    #gradients['dW3'] = 1/m * np.dot(gradients['dZ3'], activation_values['2'].T)\n",
    "    #gradients['db3'] = 1/m * np.sum(gradients['dZ3'], axis=1, keepdims=True)\n",
    "    \n",
    "    # WARSTWA 2\n",
    "    #gradients['dZ2'] = np.dot(parameters['W3'].T, gradients['dZ3']) * relu_derivative(activation_values['2']) \n",
    "    #gradients['dW2'] = 1/m * np.dot(gradients['dZ2'], activation_values['1'].T)\n",
    "    #gradients['db2'] = 1/m * np.sum(gradients['dZ2'], axis=1, keepdims=True)\n",
    "    \n",
    "    # WARSTWA 1\n",
    "    #gradients['dZ1'] = np.dot(parameters['W2'].T, gradients['dZ2']) * relu_derivative(activation_values['1']) \n",
    "    #gradients['dW1'] = 1/m * np.dot(gradients['dZ1'], activation_values['0'].T)\n",
    "    #gradients['db1'] = 1/m * np.sum(gradients['dZ1'], axis=1, keepdims=True)\n",
    "    #POWYZEJ POPRAWNE HARDCODED\n",
    "    \n",
    "    if(activation_functions[str(index)] == 'linear'):\n",
    "        #print('calling last layer, linear activation', 'index:', index)\n",
    "        activation_function_derivative = linear_derivative()\n",
    "        \n",
    "    elif(activation_functions[str(index)] == 'relu'):\n",
    "        activation_function_derivative = relu_derivative(activation_values[str(index)])\n",
    "        \n",
    "    elif(activation_functions[str(index)] == 'leaky_relu'):\n",
    "        #activation_function_derivative = leaky_relu_derivative(activation_values[str(index)])\n",
    "        activation_function_derivative = leaky_relu_derivative(activation_values[str(index)])\n",
    "    \n",
    "    elif(activation_functions[str(index)] == 'sigmoid'):\n",
    "        activation_function_derivative = sigmoid_derivative(activation_values[str(index)])\n",
    "        \n",
    "    \n",
    "    if(error_type == 'MSE'):\n",
    "        #print('idex w mid layer', index)    \n",
    "        gradients['dZ'+str(index)] = np.dot(parameters['W'+str(index + 1)].T, gradients['dZ'+str(index + 1)])  * activation_function_derivative#relu_derivative(activation_values[str(index)])\n",
    "    \n",
    "    gradients['dW'+str(index)] = 1/m * np.dot(gradients['dZ'+str(index)], activation_values[str(index - 1)].T)\n",
    "    gradients['db'+str(index)] = 1/m * np.sum(gradients['dZ'+str(index)], axis=1, keepdims=True)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_layers_back_propagation_automated(y_true, parameters, gradients, activation_values, activation_functions, z_values, no_of_layers):\n",
    "    \n",
    "    m = y_true.shape[1]\n",
    "    \n",
    "    for i in reversed(range(1,no_of_layers)):\n",
    "        \n",
    "        if(i == no_of_layers - 1):            \n",
    "            last_layer_back_propagation(gradients, activation_values, activation_functions,z_values,'MSE',i,y_true)\n",
    "        \n",
    "        else:\n",
    "            mid_layer_back_propagation_vol_two(parameters,gradients,activation_values,activation_functions,z_values,'MSE',i,y_true)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(y_hat, y_true, error_type = None):\n",
    "    \n",
    "    n_examples = y_hat.shape[1]\n",
    "    \n",
    "    if(error_type == 'MSE'):\n",
    "        return 1/n_examples * np.sum((y_true - y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_activation_values(activation_values):\n",
    "    for key, value in activation_values.items():\n",
    "        print(key)\n",
    "        print(value.shape)\n",
    "        print(value)\n",
    "        print('liczba wartosci wiekszych niz 0', np.sum(value > 1))\n",
    "        print(\"-------\")\n",
    "        \n",
    "        if(key == '3'):\n",
    "            print('xdddddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, no_of_layers, learning_rate = 0.001):#0.001\n",
    "    \n",
    "    for i in range(1,no_of_layers):\n",
    "        parameters['W' + str(i)] -= learning_rate * gradients['dW'+str(i)]\n",
    "        parameters['b' + str(i)] -= learning_rate * gradients['db' + str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_regression(x_train, y_train, layers, no_of_iterations = 5000, include_bias = True, error_type='MSE'):\n",
    "    parameters , activation_values = initialize_parameters(x_train, layers, include_bias)\n",
    "    \n",
    "    g_values = {}\n",
    "    g_prime_values = {}\n",
    "    activation_functions = get_activation_functions(layers) # {'0': 'relu', '1': 'sigmoid', ...}\n",
    "    z_values = {}\n",
    "    gradients = {}\n",
    "    losses = []\n",
    "    \n",
    "    no_of_layers = len(layers)\n",
    "    \n",
    "    for i in range(1,no_of_iterations): #5000 \n",
    "        all_layers_forward_propagation(parameters, activation_values, activation_functions, z_values, no_of_layers)\n",
    "        \n",
    "        #if(i%50 == 0):\n",
    "        losses.append(calculate_error(activation_values[str(no_of_layers - 1)], y_train, error_type))\n",
    "        #all_layers_back_propagation_hardcoded_hardcoded(y_train,parameters, gradients, activation_values, activation_functions, z_values, no_of_layers)\n",
    "        \n",
    "        #ponizsze odkomentowac dla wstecznej propagacji\n",
    "        all_layers_back_propagation_automated(y_train,parameters,gradients,activation_values,activation_functions,z_values,no_of_layers)\n",
    "        \n",
    "        #ponizsze odkomentowac dla update parameters\n",
    "        update_parameters(parameters,gradients,no_of_layers)\n",
    "        \n",
    "    #print(losses)\n",
    "   # print_activation_values(activation_values)\n",
    "    print('ostatni blad po pierwiastkowaniu: ', np.sqrt(losses[-1]))\n",
    "    \n",
    "    #plt.figure(figsize=(20,10))\n",
    "    plt.plot(losses[:])\n",
    "    #plt.plot(losses)\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ostatni blad po pierwiastkowaniu:  30.343041368850454\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAk0klEQVR4nO3deXxc9Xnv8c8zo12WkGTLsi3ZyAbbeMG1sWJMDTQkBBxCghNSljSYtvQ6UJJCk9skNE2b5ia9CW2gIWmda5YEUtawxIQlgbDEQGyMDN73FcuWLXmVbGuf5/4xR2ZsZEuWJc1o5vt+veY1Z55zzszzY3nmp9/5zfmZuyMiIqkhFO8ERESk76joi4ikEBV9EZEUoqIvIpJCVPRFRFJIWrwT6MygQYO8vLw83mmIiPQrS5Ys2ePuxcfHE77ol5eXU1lZGe80RET6FTPb1lFcwzsiIilERV9EJIWo6IuIpBAVfRGRFKKiLyKSQlT0RURSiIq+iEgKSdqi/+Aft/Lssp3xTkNEJKEkbdF/dPH7PLtURV9EJFbSFv2BAzLYd7gp3mmIiCSUpC36RbmZ7DvcHO80REQSStIW/YG5GexV0RcROUbSFv2i3AzqG1tpbo3EOxURkYSRtEW/MDcDgP1H1NsXEWmXtEV/YFD09x5S0RcRaddp0Tez4Wb2mpmtMbNVZnZbEH/czJYGj61mtjSIl5tZQ8y+n8W811QzW2FmG83sHjOz3mpYkXr6IiIf0pVFVFqBr7n7u2aWBywxs5fd/dr2A8zsR8DBmHM2ufvkDt5rLjAHWAS8AMwEXuxu8idztKevi7kiIkd12tN392p3fzfYrgfWAKXt+4Pe+jXAoyd7HzMbCuS7+0J3d+AhYFb3Uz+59p7+vkOaqy8i0u6UxvTNrByYArwdE74I2O3uG2JiI83sPTP7g5ldFMRKgaqYY6qI+fI47nPmmFmlmVXW1taeSopHFeRkYIbm6ouIxOhy0TezAcBTwO3uXhez63qO7eVXAyPcfQrwVeARM8sHOhq/944+y93nuXuFu1cUF39oXd8uCYeMwhzN1RcRidWlhdHNLJ1owX/Y3Z+OiacBnwOmtsfcvQloCraXmNkmYAzRnn1ZzNuWAb16c5yi3Az19EVEYnRl9o4B9wNr3P2u43ZfCqx196qY44vNLBxsjwJGA5vdvRqoN7PpwXvOBub3UDs6VKRf5YqIHKMrwzszgBuAj8VMw7wi2HcdH76AezGw3MyWAU8CN7v7vmDfLcB9wEZgE700c6fdoAEZ7NWFXBGRozod3nH3N+l4PB53/8sOYk8RHQrq6PhKYOKppdh9g/OyeGPDnr76OBGRhJe0v8gFKM7LpL6xlYbmtninIiKSEJK66JfkZwFQU98Y50xERBJDUhf9wXmZANTUa1xfRASSvOi39/R316mnLyICSV7023v6u+vU0xcRgSQv+gU56WSEQxrTFxEJJHXRNzOK8zKpUU9fRARI8qIPUJKfqZ6+iEgg6Yv+4LwsjemLiASSvuiX5GdSo9k7IiJAChT9wflZ1OlXuSIiQAoU/WEF0bn6Ow40xDkTEZH4S/qiX1qQA6joi4hAKhT9wmwAduxX0RcRSfqiX5KXSThk7DhwJN6piIjEXdIX/bRwiCH5Werpi4iQAkUfokM8GtMXEenaGrnDzew1M1tjZqvM7LYg/h0z29HBEoqY2R1mttHM1pnZ5THxqWa2Ith3T7BWbq8rK8hWT19EhC4slwi0Al9z93fNLA9YYmYvB/vudvf/iD3YzMYTXTt3AjAM+L2ZjXH3NmAuMAdYBLwAzKSX18mFaE9/V10jLW0R0sMp8ceNiEiHOq2A7l7t7u8G2/XAGqD0JKdcBTzm7k3uvoXoIujTzGwokO/uC93dgYeAWafbgK4oLcgm4rDroH6ZKyKp7ZS6vWZWDkwB3g5CXzaz5Wb2gJkVBrFSYHvMaVVBrDTYPj7e0efMMbNKM6usra09lRQ7dHTapsb1RSTFdbnom9kA4CngdnevIzpUcxYwGagGftR+aAen+0niHw66z3P3CnevKC4u7mqKJ1RWGP2B1vZ9mrYpIqmtS0XfzNKJFvyH3f1pAHff7e5t7h4B7gWmBYdXAcNjTi8Ddgbxsg7iva6sMJtwyNi693BffJyISMLqyuwdA+4H1rj7XTHxoTGHfRZYGWw/C1xnZplmNhIYDSx292qg3symB+85G5jfQ+04qfRwiBFFOWzdo56+iKS2rszemQHcAKwws6VB7B+B681sMtEhmq3AlwDcfZWZPQGsJjrz59Zg5g7ALcAvgGyis3Z6feZOu/KBOWzeo56+iKS2Tou+u79Jx+PxL5zknO8D3+8gXglMPJUEe0r5oFze3rIPd6ePfh4gIpJwUmbS+shBuRxpbqOmXqtoiUjqSqmiD7BFQzwiksJSpuiXD4wW/a0q+iKSwlKm6A8ryCYjHFJPX0RSWsoU/XDIGFWcy8aaQ/FORUQkblKm6AOMKclj7a76eKchIhI3KVX0xw7JY8eBBuobW+KdiohIXKRW0S/JA2CDhnhEJEWlVtEfEi366zTEIyIpKqWKfmlBNjkZYRV9EUlZKVX0QyFjTEke63er6ItIakqpog/Rcf21u+qJLt4lIpJaUq7oTyjNZ9/hZnZq6UQRSUEpV/QnlRUAsKLqQFzzEBGJh5Qr+ucMySMtZCyvOhjvVERE+lzKFf2s9DDnDM1T0ReRlNSV5RKHm9lrZrbGzFaZ2W1B/N/NbK2ZLTezZ8ysIIiXm1mDmS0NHj+Lea+pZrbCzDaa2T0Wp9VMzi0tYHnVAV3MFZGU05WefivwNXcfB0wHbjWz8cDLwER3nwSsB+6IOWeTu08OHjfHxOcCc4iumzsamNkTjThVk8rOoK6xlW17tWauiKSWTou+u1e7+7vBdj2wBih195fcvTU4bBFQdrL3CRZSz3f3hR7tYj8EzDqd5LtrUtkZACzTxVwRSTGnNKZvZuXAFODt43b9Nccucj7SzN4zsz+Y2UVBrBSoijmmKoj1ubEleeRkhFmybX88Pl5EJG46XRi9nZkNAJ4Cbnf3upj4t4gOAT0chKqBEe6+18ymAr82swl0vLh6h4PqZjaH6DAQI0aM6GqKXZYWDjH1zEIWb9nX4+8tIpLIutTTN7N0ogX/YXd/OiZ+I3Al8BfBkA3u3uTue4PtJcAmYAzRnn3sEFAZsLOjz3P3ee5e4e4VxcXFp96qLvhIeRHrdtdz8IhusywiqaMrs3cMuB9Y4+53xcRnAt8APuPuR2LixWYWDrZHEb1gu9ndq4F6M5sevOdsYH6PtuYUTBtZhDtUblNvX0RSR1d6+jOAG4CPxUzDvAL4KZAHvHzc1MyLgeVmtgx4ErjZ3dsr6y3AfcBGon8BxF4H6FOThxeQHjYN8YhISul0TN/d36Tj8fgXTnD8U0SHgjraVwlMPJUEe0tWepg/KStg8VYVfRFJHSn3i9xY548qYnnVQeq0fKKIpIiULvoXjS6mLeIs3LQ33qmIiPSJlC76540oJDcjzIL1tfFORUSkT6R00c9IC3HBWQNZsKFW9+ERkZSQ0kUf4OIxxWzf18BW3YdHRFKAiv7o6I+/NMQjIqkg5Yt++aBcygfm8MramninIiLS61K+6ANcNmEICzft0dRNEUl6KvrA5RNKaGlzXlNvX0SSnIo+MGV4IcV5mfxu1a54pyIi0qtU9IFQyPjE+BJeX1dLY0tbvNMREek1KvqByycM4UhzG29u2BPvVEREeo2KfuCCUQMpyEnn2WUd3uJfRCQpqOgHMtJCfOrcoby0eheHmlo7P0FEpB9S0Y8xa0opjS0RXtIFXRFJUir6MaaOKKSsMJtfL9UQj4gkJxX9GKGQcdXkYby5oZba+qZ4pyMi0uO6skbucDN7zczWmNkqM7stiBeZ2ctmtiF4Low55w4z22hm68zs8pj4VDNbEey7J1grN6F8dkopEYf5S3fEOxURkR7XlZ5+K/A1dx8HTAduNbPxwDeBV9x9NPBK8Jpg33XABGAm8N/tC6UDc4E5RBdLHx3sTyhnD85jyogCHl38vm63LCJJp9Oi7+7V7v5usF0PrAFKgauAB4PDHgRmBdtXAY+5e5O7byG6CPo0MxsK5Lv7Qo9W04dizkko108bwabaw7yzdX+8UxER6VGnNKZvZuXAFOBtoMTdqyH6xQAMDg4rBbbHnFYVxEqD7ePjHX3OHDOrNLPK2tq+v+XxlZOGkpeZxqOL3+/zzxYR6U1dLvpmNgB4Crjd3etOdmgHMT9J/MNB93nuXuHuFcXFxV1NscfkZKQxa0opz6+o5sCR5j7/fBGR3tKlom9m6UQL/sPu/nQQ3h0M2RA8t9+isgoYHnN6GbAziJd1EE9I108bQXNrhKfe1QVdEUkeXZm9Y8D9wBp3vytm17PAjcH2jcD8mPh1ZpZpZiOJXrBdHAwB1ZvZ9OA9Z8eck3DGD8tn8vAC/mfRNiIRXdAVkeTQlZ7+DOAG4GNmtjR4XAH8APiEmW0APhG8xt1XAU8Aq4HfAre6e/utK28B7iN6cXcT8GJPNqan/dWMcrbsOcxr63SffRFJDpbo0xIrKiq8srIyLp/d0hbh4jtfY+SgXB75X9PjkoOISHeY2RJ3rzg+rl/knkR6OMTsC8r546a9rKk+2bVrEZH+QUW/E9dPG052epgH3twS71RERE6bin4nCnIyuHpqKfOX7tT9eESk31PR74KbLhxFayTC/erti0g/p6LfBSMH5XLFuUP5n0XbOHikJd7piIh0m4p+F916ydkcamrlF3/cGu9URES6TUW/i8YNzefScYP5+R+3aDlFEem3VPRPwa2XnM2BIy08vGhbvFMREekWFf1TMGVEITPOHsi9b2yhobmt8xNERBKMiv4p+ruPjWbPoSZ+uWhrvFMRETllKvqn6PxRA7l4TDH//fom6hs1k0dE+hcV/W74h8vGcuBIC/e9oXn7ItK/qOh3w7llZ/DJiUO4743N7DusRVZEpP9Q0e+mr35iDA0tbcx9fWO8UxER6TIV/W4aXZLHZ6eU8eDCbew80BDvdEREukRF/zTcfuloAP79d+vinImISNeo6J+G4UU53HThSJ55bwfLth+IdzoiIp3qyhq5D5hZjZmtjIk9HrN04lYzWxrEy82sIWbfz2LOmWpmK8xso5ndE6yT2+/97UfPYtCADP7Pc6tJ9FXIRES60tP/BTAzNuDu17r7ZHefDDwFPB2ze1P7Pne/OSY+F5hDdKH00ce/Z3+Vl5XO1y4bS+W2/bywYle80xEROalOi767LwD2dbQv6K1fAzx6svcws6FAvrsv9Gh3+CFg1ilnm6CuqRjOOUPy+L8vrqGxRbdnEJHEdbpj+hcBu919Q0xspJm9Z2Z/MLOLglgpUBVzTFUQ65CZzTGzSjOrrK2tPc0Ue184ZHz7yvFU7W/QQisiktBOt+hfz7G9/GpghLtPAb4KPGJm+UBH4/cnHAB393nuXuHuFcXFxaeZYt+YcfYgLp9Qwk9f3UjV/iPxTkdEpEPdLvpmlgZ8Dni8PebuTe6+N9heAmwCxhDt2ZfFnF4G7OzuZyeqf/70BAD+9Ter45yJiEjHTqenfymw1t2PDtuYWbGZhYPtUUQv2G5292qg3symB9cBZgPzT+OzE1JpQTa3XTqal1fv5verd8c7HRGRD+nKlM1HgYXAWDOrMrObgl3X8eELuBcDy81sGfAkcLO7t18EvgW4D9hI9C+AF3sg/4Tz1zNGMnrwAL7zm1W6576IJBxL9LnlFRUVXllZGe80Tsnbm/dy7bxF3HrJWfzD5efEOx0RSUFmtsTdK46P6xe5veD8UQP53HmlzFuwmbW76uKdjojIUSr6veSfPjWe/Kx0vv7kclrbIvFOR0QEUNHvNUW5GXz3qoksrzrIvVpsRUQShIp+L7ri3CHMnDCEu3+/no01h+KdjoiIin5vMjO+O2sCORlhvv7kMtoiiX3RXESSn4p+Lxucl8W/fHo8775/gJ+/pWEeEYkvFf0+MGtyKZeOK+HO365jTbVm84hI/Kjo9wEz44dXn0t+djq3P7ZUd+IUkbhR0e8jAwdk8h9/Pol1u+v54W/XxjsdEUlRKvp96KNjB/OXf1rOz9/ayh/WJ/4to0Uk+ajo97FvfvIcxpQM4H//ahl7DzXFOx0RSTEq+n0sKz3Mj6+bwsGGFm5/fKmmcYpIn1LRj4NxQ/P57mcm8MaGPfzk1Q2dnyAi0kNU9OPk2o8M53PnlfLjVzawQOP7ItJHVPTjxMz43qyJjB48gNsfX0r1wYZ4pyQiKUBFP45yMtKY+8WpNLW0cevD79Lcqrtxikjv6srKWQ+YWY2ZrYyJfcfMdpjZ0uBxRcy+O8xso5mtM7PLY+JTzWxFsO+eYNnElHdW8QB++PlJvPv+Ab7965Uk+qI2ItK/daWn/wtgZgfxu919cvB4AcDMxhNdRnFCcM5/t6+ZC8wF5hBdN3f0Cd4zJV05aRhfvuRsHq/czs/f2hrvdEQkiXVa9N19AbCvs+MCVwGPuXuTu28huh7uNDMbCuS7+0KPdmUfAmZ1M+ek9NVPjOGy8SV87/nVurArIr3mdMb0v2xmy4Phn8IgVgpsjzmmKoiVBtvHxyUQChl3XzuZMSV5fPmRd9lcq/vvi0jP627RnwucBUwGqoEfBfGOxun9JPEOmdkcM6s0s8ra2tTp9eZmpnHv7ArSwiFuerCSfYeb452SiCSZbhV9d9/t7m3uHgHuBaYFu6qA4TGHlgE7g3hZB/ETvf88d69w94ri4uLupNhvDS/KYd4NU9lxoIGbHnyHhmbdkVNEek63in4wRt/us0D7zJ5ngevMLNPMRhK9YLvY3auBejObHszamQ3MP428k1pFeRH3XDeZpdsP8JVH39PC6iLSY7oyZfNRYCEw1syqzOwm4M5g+uVy4BLg7wHcfRXwBLAa+C1wq7u3d1VvAe4jenF3E/BiTzcmmcycOJTvfHoCv1+zm2/PX6WpnCLSI9I6O8Ddr+8gfP9Jjv8+8P0O4pXAxFPKLsXd+Kfl7KprZO7rmxiSn8Vtl46Od0oi0s91WvQlvr5++Vhq6pq4+/fryc0M8zcXjYp3SiLSj6noJ7j2pRYbWlr53vNryEwPc8P0M+Odloj0Uyr6/UBaOMR/XjuF5tYlfPvXK8lMC3FNxfDOTxQROY5uuNZPZKSF+OkXzuOi0YP4xlPLmb90R7xTEpF+SEW/H8lKDzPvhgqmlRfx948v5VeV2zs/SUQkhop+P5OdEebnf/URZpw9iH94cjm/XLg13imJSD+iot8P5WREb9dw6bjBfHv+KuYt2BTvlESkn1DR76ey0sPM/eJUPjVpKP/2wlruenm9fsAlIp3S7J1+LD0c4p7rppCTHuaeVzaw+2Aj3/vsRNLD+i4XkY6p6Pdz4ZBx5+cnMeSMLH7y6kZ21zfyX184j9xM/asVkQ9TlzAJmBlfu2ws//bZc1mwvpbr5i2itr4p3mmJSAJS0U8iXzh/BPfOrmBjzSFm/ddbrN5ZF++URCTBqOgnmY+PK+HxL02nNRLh6rl/5IUV1fFOSUQSiIp+EppUVsBvvnwh44bm8bcPv8uPXlpHJKKZPSKiop+0Budn8eic6VxTUcZPXt3InF8u4WBDS7zTEpE4U9FPYplpYX549SS+8+nxvL6uhit/8gbLth+Id1oiEkcq+knOzPjLGSN54uYLiETg8z/7Iw+8uUU/5BJJUV1ZLvEBM6sxs5UxsX83s7VmttzMnjGzgiBebmYNZrY0ePws5pypwRKLG83snmCtXOkj540o5Pm/u5A/GzOY7z63mjm/XMKBI83xTktE+lhXevq/AGYeF3sZmOjuk4D1wB0x+za5++TgcXNMfC4wh+hi6aM7eE/pZQU5Gdw7eyr/9KlxvL6uhsvuXsBr62rinZaI9KFOi767LwD2HRd7yd1bg5eLgLKTvYeZDQXy3X2hR8cVHgJmdStjOS1mxt9cNIpn/nYGBTnp/NXP3+GOp1dwuKm185NFpN/riTH9vwZejHk90szeM7M/mNlFQawUqIo5piqIdcjM5phZpZlV1tbW9kCKcryJpWfwm69cyJf+bBSPvfM+M3+8gLc37413WiLSy06r6JvZt4BW4OEgVA2McPcpwFeBR8wsH+ho/P6EVxLdfZ67V7h7RXFx8emkKCeRmRbmjk+O44kvXYBhXDtvEXc8vZyDRzS1UyRZdbvom9mNwJXAXwRDNrh7k7vvDbaXAJuAMUR79rFDQGXAzu5+tvSsj5QX8dvbL2LOxaN4orKKj9/1OvOX7tAMH5Ek1K2ib2YzgW8An3H3IzHxYjMLB9ujiF6w3ezu1UC9mU0PZu3MBuafdvbSY3Iy0vjHK8bx7JdnUFqYw22PLWX2A4vZsudwvFMTkR7UlSmbjwILgbFmVmVmNwE/BfKAl4+bmnkxsNzMlgFPAje7e/tF4FuA+4CNRP8CiL0OIAliwrAzePqWP+W7V03gvfcPcNndf+B7z63Wr3lFkoQl+p/wFRUVXllZGe80UlJNfSN3vbSexyu3U5CdzlcvG8v1HxlOmhZpEUl4ZrbE3SuOj+v/XjmhwXlZ/ODqSTz3lQsZU5LHt3+9kk/++A1+t2qXxvtF+ikVfenUhGFn8Nic6fzsi1NpjThf+uUSZv3XWyxYX6viL9LPqOhLl5gZMycO4eW/v5g7r57EnkPNzH5gMdf+v0Wa3y/Sj2hMX7qlqbWNx9/Zzk9e3UhtfRPTyou4+aOjuGTsYHRbJZH4O9GYvoq+nJaG5jYee+d97ntjCzsONHDOkDxu/rOzuHLSUF3wFYkjFX3pVS1tEX6zbCdzX9/EhppDlBVmM/uCM7mmYjgFORnxTk8k5ajoS5+IRJxX19Ywb8FmFm/dR1Z6iFmTS5l9QTnjh+XHOz2RlKGiL31uTXUdDy3cxjPvVdHYEmFaeRFfOH8El08YQnZGON7piSQ1FX2Jm4NHWvjVku38ctE2tu09Ql5mGlf+yVA+P3U4540o0IVfkV6goi9xF4k4b2/Zx6+WbOfFFbtoaGnjrOJcrp5axqcnDWN4UU68UxRJGir6klAONbXy/PKd/Kqyispt+wGYPLyAKycN5YpzhzKsIDvOGYr0byr6krDe33uE51dU8/yKnazcUQfA1DMLueLcoXxiXAkjBuovAJFTpaIv/cKWPYd5YUU1zy2vZk119Atg9OABfHxcCR8fN5jzRhQSDukagEhnVPSl39m29zCvrKnhlbW7eXvzPlojTmFOOpeMHcyFowcx4+xBlORnxTtNkYSkoi/9Wl1jC2+s38Mra3bz+vpa9h1uBuDswQOYcdZAZpw9iOlnDSQ/Kz3OmYokBhV9SRqRiLNmVx1vbdzDWxv3snjLPhpa2ghZdMH3qWcWUnFmERXlhfpLQFKWir4krabWNpa+f4C3Nu7h7S37WFZ1gMaWCABlhdlUnFnI1PIizhtRwJiSPNJ1TyBJAScq+mldOPEBogug17j7xCBWBDwOlANbgWvcfX+w7w7gJqAN+Dt3/10Qnwr8AsgGXgBu80T/xpF+ITMtzPmjBnL+qIEANLdGWF1dR+XWfSzZtp+3Nu3l10t3ApCRFmLckDwmlp7BuaVnMLH0DMYO0ReBpI5Oe/pmdjFwCHgopujfCexz9x+Y2TeBQnf/hpmNBx4FpgHDgN8DY9y9zcwWA7cBi4gW/XvcvdN1ctXTl9Pl7mzf18DSqgOs3HGQ5VUHWLWjjvqmVgAywiHOGZrHOUPyGFMSfYwdksfgvEz9Wlj6rW739N19gZmVHxe+CvhosP0g8DrwjSD+mLs3AVvMbCMwzcy2AvnuvjBI5iFgFlocXfqAmTFiYA4jBubwmT8ZBkSvC2zbd4QVOw6yMni8uraGJyqrjp53RnY6Y0vyGF0ygLFD8hg5KJfygbkMK8jWtFHptzot+idQ4u7VAO5ebWaDg3gp0Z58u6og1hJsHx/vkJnNAeYAjBgxopspipxYKGSMHJTLyEG5R78IAPYeamL97kOs313Put31bNhdz2+W7eTht1uPHpMRDjFiYA7lA3MZOSiH8kG5jByYy5mDcinJy9Q6ApLQulv0T6Sj7o+fJN4hd58HzIPo8E7PpCbSuYEDMrlgQCYXnDXwaMzdqalvYnPtYbbuPczWPYfZsie6vWBDLc2tkaPHhkPGkPwsSguzKSvIprQwm9KCbIbFbGel6w6jEj/dLfq7zWxo0MsfCtQE8SpgeMxxZcDOIF7WQVwk4ZkZJflZlORnHfNlANFhouq6RrbuOcy2vUfYceAIO/Y3sONAA4s272VXXSOR47othTnpDM7LYnB+ZsxzJiX5WUefi/My9eUgvaK7Rf9Z4EbgB8Hz/Jj4I2Z2F9ELuaOBxcGF3Hozmw68DcwGfnJamYskgFDIKC2I9uBnnP3h/S1tEXYdbGTngegXwY79Deyqa6Smvoma+iY21uyhtr6J1uO/GYC8rDQG5mZQmJtBUU4GRbnRR2HwXJQT3W4/Ji8zjZCuNUgnujJl81GiF20HmVkV8C9Ei/0TZnYT8D7w5wDuvsrMngBWA63Are7eFrzVLXwwZfNFdBFXUkB6OMTwopyT3jY6EnH2H2lmd10TNfXBF0JdI7X1Tew70sL+w81UH2xk1c469h1uprkt0uH7hAzystLJz04jPys9+shOi8Zi49np5GelkZ+dzoDMNHIz08jNCJOTmUZOelhfHElOP84S6UfcnSPNbew73Bx9HGlmf7B9sKGFuoYW6hpbqW9soa6hlbrGD2KHmlo7/wAgOz1MbmaYnIw0cjLC5GYGzxlp5GR+8JydHiYrPUxWWojM9DBZ6SGy0sJkHn0Ok5kWih6THiIzLTgmPUxayDQdtpd1e8qmiCQOM4v2zDPTTnnRmda2CIeaWj/4Mmhsob6xlYbmNg43t3KkKXhubuNw07HP9Y2t7K5r5HBTG0eaWznc3HbMBexTFTKCL4MwGeEQ6WlGejhEeihmOxyK7gsHr9OOex0OkZF27Ov27bRwiLSQETYjHDLSwkbILBqLeaSFQoRCkBYKxcSOPyY4NxzELHpeOBzdDoUgZNFtMxL+y0xFXyRFpIVDFORkUJCT0SPv1xZxmlrbaGyJ0NjSRlPrsc/HxFoiHR7b2NpGS6vT0hahuS1CS1uElrbgdWuEI82ttEac5tZj97Xvb3/d0TWReDGLfgmEjj7HbIc+2DYzwqEPjmk/Lxz6YPu5r1zY4xf0VfRFpFvCIQuGgOKdSfS6SEsk+BJojdASiRCJQGvMc1vEaXOntc2PbrdFoq8j7rRGnLZIhLYItEUiwevgmIgTifgxsaNxj+6LOETccY9ut7kHr6P5tbVvB/G2CMGxwbmRmO3g2N74EaCKvoj0e6GQkRkKk5kGZMY7m8Smnw6KiKQQFX0RkRSioi8ikkJU9EVEUoiKvohIClHRFxFJISr6IiIpREVfRCSFJPwN18ysFtjWzdMHAXt6MJ3+QG1ODWpz8jvd9p7p7sXHBxO+6J8OM6vs6C5zyUxtTg1qc/LrrfZqeEdEJIWo6IuIpJBkL/rz4p1AHKjNqUFtTn690t6kHtMXEZFjJXtPX0REYqjoi4ikkKQs+mY208zWmdlGM/tmvPM5HWb2gJnVmNnKmFiRmb1sZhuC58KYfXcE7V5nZpfHxKea2Ypg3z2WwAt5mtlwM3vNzNaY2Sozuy2IJ227zSzLzBab2bKgzf8axJO2zQBmFjaz98zsueB1srd3a5DrUjOrDGJ922YPlvdKlgcQBjYBo4AMYBkwPt55nUZ7LgbOA1bGxO4EvhlsfxP4YbA9PmhvJjAy+OcQDvYtBi4ADHgR+GS823aSNg8Fzgu284D1QduStt1BfgOC7XTgbWB6Mrc5yPWrwCPAcyny3/ZWYNBxsT5tczL29KcBG919s7s3A48BV8U5p25z9wXAvuPCVwEPBtsPArNi4o+5e5O7bwE2AtPMbCiQ7+4LPfpfzEMx5yQcd69293eD7XpgDVBKErfbow4FL9ODh5PEbTazMuBTwH0x4aRt70n0aZuTseiXAttjXlcFsWRS4u7VEC2QwOAgfqK2lwbbx8cTnpmVA1OI9nyTut3BUMdSoAZ42d2Tvc3/CXwdiMTEkrm9EP0if8nMlpjZnCDWp21OxoXROxrbSpV5qSdqe7/8Z2JmA4CngNvdve4kw5ZJ0W53bwMmm1kB8IyZTTzJ4f26zWZ2JVDj7kvM7KNdOaWDWL9pb4wZ7r7TzAYDL5vZ2pMc2yttTsaefhUwPOZ1GbAzTrn0lt3Bn3gEzzVB/ERtrwq2j48nLDNLJ1rwH3b3p4Nw0rcbwN0PAK8DM0neNs8APmNmW4kOwX7MzP6H5G0vAO6+M3iuAZ4hOhzdp21OxqL/DjDazEaaWQZwHfBsnHPqac8CNwbbNwLzY+LXmVmmmY0ERgOLgz8Z681senCVf3bMOQknyPF+YI273xWzK2nbbWbFQQ8fM8sGLgXWkqRtdvc73L3M3cuJ/j/6qrt/kSRtL4CZ5ZpZXvs2cBmwkr5uc7yvZvfGA7iC6IyPTcC34p3PabblUaAaaCH6DX8TMBB4BdgQPBfFHP+toN3riLmiD1QE/4FtAn5K8GvsRHwAFxL9c3U5sDR4XJHM7QYmAe8FbV4J/HMQT9o2x+T7UT6YvZO07SU6o3BZ8FjVXpv6us26DYOISApJxuEdERE5ARV9EZEUoqIvIpJCVPRFRFKIir6ISApR0RcRSSEq+iIiKeT/AyMD7R5yhTb5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x_train, layers, no_of_iterations = 5001, include_bias = True\n",
    "new_parameters = neural_network_regression(x_train, y_train, layers, no_of_iterations = 5000, include_bias = include_bias) \n",
    "    #zmienic drugi parametr na y_train gdy będzie znany\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[20.0850003]]), 'b1': array([[-43.02587672]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_regression(parameters, x_test, layers):\n",
    "    activation_functions = get_activation_functions(layers)\n",
    "    activation_values = {'0': x_test}\n",
    "    z_values = {}\n",
    "    \n",
    "    predicted_values_regression = all_layers_forward_propagation(parameters,activation_values,activation_functions,\n",
    "                                                     z_values, no_of_layers=len(layers))\n",
    "    return predicted_values_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(regression_problem):\n",
    "    y_predicted_values_regression = predict_regression(new_parameters, x_test, layers)\n",
    "    \n",
    "    plt.scatter(*x_train,*y_train, color='blue', s=10)\n",
    "    plt.scatter(*x_test,*y_test, color='red', s=0.5)\n",
    "    plt.show()\n",
    "#with np.printoptions(threshold=np.inf):\n",
    "    #print(arr)--\n",
    "    #print((y_test - y_predicted_values_regression).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
